#!/usr/bin/env python3
"""
Test Enhanced Weekly Batch Processing
Demonstrates realistic MLOps workflows using weekly Premier League data batches
"""

import os
import sys

sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", "src"))

import logging
from datetime import datetime

from orchestration.batch_processor import WeeklyBatchProcessor

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def test_batch_processor():
    """Test the weekly batch processor with real Premier League data"""
    logger.info("üèà Testing Weekly Batch Processor")
    logger.info("=" * 60)

    try:
        # Initialize processor
        processor = WeeklyBatchProcessor()

        # Test 1: Get recent weeks
        logger.info("üìÖ Test 1: Recent weeks processing")
        recent_batches = processor.get_recent_weeks(3)

        for i, batch in enumerate(recent_batches, 1):
            logger.info(f"  Week {i}: {batch.week_id} - {batch.total_matches} matches")
            logger.info(
                f"    Period: {batch.week_start.strftime('%Y-%m-%d')} to {batch.week_end.strftime('%Y-%m-%d')}"
            )

            # Show a sample match from the batch
            if batch.matches:
                sample_match = batch.matches[0]
                logger.info(
                    f"    Sample: {sample_match['home_team']} vs {sample_match['away_team']} ({sample_match['result']})"
                )

        # Test 2: Get batch statistics
        logger.info("\nüìä Test 2: Batch statistics")
        stats = processor.get_batch_statistics(recent_batches)
        logger.info(f"  Total matches: {stats['total_matches']}")
        logger.info(f"  Average matches/week: {stats['avg_matches_per_week']:.1f}")
        logger.info(f"  Home win rate: {stats['result_distribution']['home_win_rate']:.1%}")
        logger.info(
            f"  Result distribution: H={stats['result_distribution']['home_wins']}, D={stats['result_distribution']['draws']}, A={stats['result_distribution']['away_wins']}"
        )

        # Test 3: Live processing simulation
        logger.info("\nüîÑ Test 3: Live processing simulation")
        simulation = processor.simulate_live_processing(weeks_back=8, weeks_ahead=2)

        logger.info(f"  Historical weeks: {simulation['simulation_summary']['historical_weeks']}")
        logger.info(f"  Upcoming weeks: {simulation['simulation_summary']['upcoming_weeks']}")
        logger.info(
            f"  Historical matches: {simulation['simulation_summary']['total_historical_matches']}"
        )
        logger.info(
            f"  Upcoming matches: {simulation['simulation_summary']['total_upcoming_matches']}"
        )
        logger.info(f"  Current simulation date: {simulation['current_date']}")

        # Test 4: Save and load batch
        logger.info("\nüíæ Test 4: Save and load batch")
        if recent_batches:
            test_batch = recent_batches[0]
            saved_path = processor.save_batch_to_file(test_batch)
            logger.info(f"  Saved batch to: {saved_path}")

            # Load it back
            loaded_batch = processor.load_batch_from_file(saved_path)
            logger.info(
                f"  Loaded batch: {loaded_batch.week_id} with {loaded_batch.total_matches} matches"
            )

        logger.info("\n‚úÖ All batch processor tests passed!")
        return True

    except Exception as e:
        logger.error(f"‚ùå Batch processor test failed: {e}")
        import traceback

        traceback.print_exc()
        return False


def test_weekly_predictions():
    """Test weekly batch predictions using real match data"""
    logger.info("\nüîÆ Testing Weekly Predictions")
    logger.info("=" * 60)

    try:
        # Import prediction components
        from monitoring.metrics_storage import MetricsStorage
        from pipelines.prediction_pipeline import PredictionPipeline

        # Initialize components
        processor = WeeklyBatchProcessor()
        pipeline = PredictionPipeline()
        metrics_storage = MetricsStorage()

        # Get a recent week for testing
        recent_batches = processor.get_recent_weeks(1)
        if not recent_batches:
            logger.warning("No recent batches found for testing")
            return False

        test_batch = recent_batches[0]
        logger.info(
            f"Testing predictions for week {test_batch.week_id} with {test_batch.total_matches} matches"
        )

        correct_predictions = 0
        total_predictions = 0

        # Process a few matches from the batch
        test_matches = test_batch.matches[:5]  # Test first 5 matches

        for i, match in enumerate(test_matches, 1):
            try:
                logger.info(f"\n  Match {i}: {match['home_team']} vs {match['away_team']}")
                logger.info(f"    Actual result: {match['result']}")

                # Generate prediction
                prediction_result = pipeline.predict_match(
                    home_team=match["home_team"],
                    away_team=match["away_team"],
                    home_odds=match.get("home_odds", 2.0),
                    away_odds=match.get("away_odds", 3.0),
                    draw_odds=match.get("draw_odds", 3.5),
                )

                predicted = prediction_result["prediction"]
                confidence = prediction_result["confidence"]
                actual = match["result"]
                is_correct = predicted == actual

                logger.info(f"    Predicted: {predicted} (confidence: {confidence:.2f})")
                logger.info(f"    Correct: {'‚úÖ' if is_correct else '‚ùå'}")

                if is_correct:
                    correct_predictions += 1
                total_predictions += 1

                # Store prediction for monitoring
                prediction_data = {
                    "match_id": f"{match['home_team']}vs{match['away_team']}_{match['date']}",
                    "prediction": predicted,
                    "confidence": confidence,
                    "actual_result": actual,
                    "home_team": match["home_team"],
                    "away_team": match["away_team"],
                    "match_date": match["date"],
                }
                metrics_storage.store_prediction(prediction_data)

            except Exception as e:
                logger.warning(f"    Error predicting match: {e}")
                continue

        # Calculate accuracy
        if total_predictions > 0:
            accuracy = correct_predictions / total_predictions
            logger.info("\nüìä Weekly batch prediction results:")
            logger.info(f"  Correct predictions: {correct_predictions}/{total_predictions}")
            logger.info(f"  Accuracy: {accuracy:.2%}")

            # Store batch metrics
            metrics_storage.store_model_metric(
                model_name="premier_league_predictor",
                metrics={
                    "weekly_batch_accuracy": accuracy,
                    "batch_week": test_batch.week_id,
                    "batch_matches": total_predictions,
                },
            )

        logger.info("‚úÖ Weekly predictions test completed!")
        return True

    except Exception as e:
        logger.error(f"‚ùå Weekly predictions test failed: {e}")
        import traceback

        traceback.print_exc()
        return False


def test_realistic_mlops_workflow():
    """Test a realistic MLOps workflow with weekly batches"""
    logger.info("\nüéØ Testing Realistic MLOps Workflow")
    logger.info("=" * 60)

    try:
        processor = WeeklyBatchProcessor()

        # Simulate a realistic scenario: process last 4 weeks as if they're happening now
        logger.info("üîÑ Simulating 4-week processing cycle...")

        # Get recent batches
        batches = processor.get_recent_weeks(4)

        workflow_results = {
            "total_weeks": len(batches),
            "total_matches": 0,
            "weekly_accuracies": [],
            "workflow_timestamp": datetime.now().isoformat(),
        }

        # Process each week sequentially (simulating time progression)
        for week_num, batch in enumerate(batches, 1):
            logger.info(f"\n  üìÖ Processing Week {week_num}: {batch.week_id}")
            logger.info(f"      Matches: {batch.total_matches}")
            logger.info(
                f"      Period: {batch.week_start.strftime('%Y-%m-%d')} to {batch.week_end.strftime('%Y-%m-%d')}"
            )

            # Simulate processing results
            simulated_accuracy = 0.58 + (week_num * 0.02)  # Gradually improving accuracy
            workflow_results["weekly_accuracies"].append(
                {
                    "week": batch.week_id,
                    "matches": batch.total_matches,
                    "accuracy": simulated_accuracy,
                }
            )
            workflow_results["total_matches"] += batch.total_matches

            logger.info(f"      Simulated accuracy: {simulated_accuracy:.2%}")

            # Simulate alerts for poor performance
            if simulated_accuracy < 0.55:
                logger.warning("      üö® Performance alert: accuracy below threshold!")

        # Calculate overall workflow metrics
        overall_accuracy = sum(w["accuracy"] for w in workflow_results["weekly_accuracies"]) / len(
            workflow_results["weekly_accuracies"]
        )
        workflow_results["overall_accuracy"] = overall_accuracy

        logger.info("\nüìà Workflow Summary:")
        logger.info(f"  Weeks processed: {workflow_results['total_weeks']}")
        logger.info(f"  Total matches: {workflow_results['total_matches']}")
        logger.info(f"  Overall accuracy: {overall_accuracy:.2%}")
        logger.info(
            f"  Average matches/week: {workflow_results['total_matches'] / workflow_results['total_weeks']:.1f}"
        )

        # Simulate trend analysis
        if len(workflow_results["weekly_accuracies"]) >= 2:
            early_accuracy = workflow_results["weekly_accuracies"][0]["accuracy"]
            recent_accuracy = workflow_results["weekly_accuracies"][-1]["accuracy"]
            trend = recent_accuracy - early_accuracy

            logger.info(f"  Performance trend: {'+' if trend > 0 else ''}{trend:.2%}")
            if trend < -0.05:
                logger.warning("  üö® Negative trend detected!")

        logger.info("‚úÖ Realistic MLOps workflow test completed!")
        return True

    except Exception as e:
        logger.error(f"‚ùå Realistic MLOps workflow test failed: {e}")
        import traceback

        traceback.print_exc()
        return False


def main():
    """Run all weekly processing tests"""
    logger.info("üöÄ Starting Enhanced Weekly Processing Tests")
    logger.info("=" * 80)

    tests = [
        ("Batch Processor", test_batch_processor),
        ("Weekly Predictions", test_weekly_predictions),
        ("Realistic MLOps Workflow", test_realistic_mlops_workflow),
    ]

    results = {}

    for test_name, test_func in tests:
        logger.info(f"\nüß™ Running: {test_name}")
        try:
            results[test_name] = test_func()
        except Exception as e:
            logger.error(f"‚ùå Test {test_name} crashed: {e}")
            results[test_name] = False

    # Summary
    logger.info("\n" + "=" * 80)
    logger.info("üìä Test Results Summary")
    logger.info("=" * 80)

    passed = 0
    for test_name, passed_test in results.items():
        status = "‚úÖ PASS" if passed_test else "‚ùå FAIL"
        logger.info(f"{test_name}: {status}")
        if passed_test:
            passed += 1

    logger.info(f"\nüéØ Overall: {passed}/{len(tests)} tests passed")

    if passed == len(tests):
        logger.info("üéâ All enhanced weekly processing tests PASSED!")
        logger.info(
            "üí° The system can now process realistic weekly batches of Premier League data!"
        )
    else:
        logger.warning("‚ö†Ô∏è Some tests failed - check the logs above")

    return passed == len(tests)


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
